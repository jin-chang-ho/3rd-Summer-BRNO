{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework_ML_basics_S.ipynb의 사본","provenance":[{"file_id":"15qfsI3YUNRy5V45a6xxv87-ESsXmWp3n","timestamp":1626104166107}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SVnn1fn-qg_W"},"source":["# ML basics - Homework"]},{"cell_type":"code","metadata":{"id":"ji5N3HIlqcyR"},"source":["#######################\n","###### TODO FILL ######\n","#######################\n","\n","#@title Author { run: \"auto\" }\n","NAME = \"Jin ChangHo\" #@param {type: \"string\"}\n","EMAIL = \"ckdgh8204@naver.com\" #@param {type: \"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s5cVE8Yk-EYI"},"source":["## How to submit\n","* Create a **copy** of this notebook. \n","* Finish the assigment.\n","* Export the notebook to `.pdf` (File > Print).\n","* Send it to xnguye16@stud.fit.vutbr.cz (Add the pdf in the attachment)."]},{"cell_type":"markdown","metadata":{"id":"NAloFyXHfuJx"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"dQHE51ZxrDXW"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.stats as stats\n","from sklearn.metrics import f1_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p5MgUTNmB_GC"},"source":["## Download the dataset"]},{"cell_type":"code","metadata":{"id":"lYJccjIVCCHe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626153291525,"user_tz":-540,"elapsed":406355,"user":{"displayName":"Changho Jin","photoUrl":"","userId":"15940163417036900361"}},"outputId":"ceb23658-e9f1-4f2f-c933-9cb76b885b3f"},"source":["#!pip install gdown\n","!gdown https://drive.google.com/uc?id=1LdKFD55N4A72qTx1IK6LDW5Mo7L1g0uz\n","!unzip data.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1LdKFD55N4A72qTx1IK6LDW5Mo7L1g0uz\n","To: /content/data.zip\n","\r  0% 0.00/120k [00:00<?, ?B/s]\r100% 120k/120k [00:00<00:00, 1.05MB/s]\n","Archive:  data.zip\n","replace data/negatives.trn? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tA2wERcof4pM"},"source":["## Dataset loading\n","\n","First task of this assigment is to load the dataset. Each sample of the dataset consists of 7 features $\\mathbf{x}$ and a label $y$, thus a sample is a tuple $(\\mathbf{x}, y)$, where $\\mathbf{x} = \\begin{bmatrix}\n","  x_1 & x_2 & x_3 & ... & x_7\\end{bmatrix}^T$ and $y \\in \\{0, 1\\}$. \n","\n","Positive and negative samples are stored in `data/positives.{trn, val, tst}` and `data/negatives.{trn, val, tst}` files, respectively. `*.trn`, `*.val`, `*.tst` contains the training, validation and test set, respectively.\n","\n","**Task:** **(Total: 1 pts)**\n","\n","* Finish `DataLoader` class which takes paths to the files to positive and negative samples, respectively. (Hint: use `np.loadtxt`) \n","\n","* Extract only the **6th** feature of the samples ($x_6$) (Index of the feature is stored in `FOI` variable). \n","\n","* Store the 6th feature of the positive samples in `pos` variable member (`pos` should have a shape $(N_{pos},)$). **(0.25 pts)**\n","\n","* Store the 6th feature of the negative samples in `neg` variable member (`neg` should have a shape $(N_{neg},)$). **(0.25 pts)**\n","\n","* Concatenate all samples (`pos`, `neg`) into `xs` resulting a vector with $(N_{pos}+N_{neg},)$ shape **(0.25 pts)**\n","\n","* `targets` should contain labels of the samples, where 1 and 0 correspond to a positive and negative sample, respectively. Thus `targets` have a shape $(N_{pos}+N_{neg},)$. **(0.25 pts)**"]},{"cell_type":"code","metadata":{"id":"uPS3YZEcizWx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626153291527,"user_tz":-540,"elapsed":18,"user":{"displayName":"Changho Jin","photoUrl":"","userId":"15940163417036900361"}},"outputId":"3c8e85d9-baa1-4ab7-e8ee-fb4d0ee57fe7"},"source":["FOI = 5     # Feature of interest\n","\n","class DataLoader:\n","    def __init__(self, pos_path: str, neg_path: str):\n","        \"\"\"\n","        :param pos_path: Filepath to a \"positives.*\" file.\n","        :param neg_path: Filepath to a \"negatives.*\" file\n","        \"\"\"\n","        #######################\n","        #### TODO YOUR CODE ###\n","        #######################\n","        positive_samples = np.loadtxt(pos_path)\n","        negative_samples = np.loadtxt(neg_path)\n","        self.pos = np.array(positive_samples[FOI])\n","        self.neg = np.array(negative_samples[FOI])\n","        self.xs = np.array(positive_samples[FOI])\n","        self.xs = np.append(self.xs, self.neg)\n","        targets_list = self.xs.tolist() \n","        for i in range(7):\n","          targets_list[i] = (targets_list[i], 1)\n","        for i in range(7, 14):\n","          targets_list[i] = (targets_list[i], 0)\n","        self.targets = np.array(targets_list)\n","\n","train_set = DataLoader(pos_path=\"data/positives.trn\", neg_path=\"data/negatives.trn\")\n","val_set = DataLoader(pos_path=\"data/positives.val\", neg_path=\"data/negatives.val\")\n","test_set = DataLoader(pos_path=\"data/positives.tst\", neg_path=\"data/negatives.tst\")\n","\n","print(f\"Training set size: {train_set.xs.shape}\")\n","print(f\"Training target set size: {train_set.targets.shape}\")\n","print(f\"Training positives set size: {train_set.pos.shape}\")\n","print(f\"Training negatives set size: {train_set.neg.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training set size: (14,)\n","Training target set size: (14, 2)\n","Training positives set size: (7,)\n","Training negatives set size: (7,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nNk6Vu1oECtC"},"source":["## Plotting the data \n","\n","**Task:** **(Total: 1 pts)**\n","\n","* Implement function for plotting two separate distributions of positive and negative samples feature using histogram (Use `plt.hist`, normalize the histograms by setting `density=true`.) Set `alpha=0.5`. \n","* Display the legend, so it's clear which distribution belongs to which label (positive, negative)."]},{"cell_type":"code","metadata":{"id":"g16Zhfx1ECMP","colab":{"base_uri":"https://localhost:8080/","height":516},"executionInfo":{"status":"ok","timestamp":1626153292083,"user_tz":-540,"elapsed":566,"user":{"displayName":"Changho Jin","photoUrl":"","userId":"15940163417036900361"}},"outputId":"afdc2339-2143-49ab-caef-701ea3d69856"},"source":["def plot_data(pos: np.array, neg: np.array):\n","    \"\"\"\n","    :param pos: Positive samples\n","    :param neg: Negative samples\n","    \"\"\"\n","    #######################\n","    #### TODO YOUR CODE ###\n","    #######################\n","    plt.hist(pos, density = True, alpha = 0.5, label = \"positive\")\n","    plt.hist(neg, density = True, alpha = 0.5, label = \"negative\")\n","    plt.legend()\n","    plt.show()\n","\n","plot_data(pos=train_set.pos, neg=train_set.neg)\n","plot_data(pos=val_set.pos, neg=val_set.neg)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXRElEQVR4nO3df3DV9b3n8edrAQmuP0Ckdyo/JHpViECDRsoO1x/1B6LbynUKNS1OcbClqExpre6iVet6dUrVVbeWFtmWpWNRQChXxvGOdSN3O9NqJdGIBkQDpghllRsq119YI+/943zJHmMgJ+THCZ+8HjNn8v3x+X7P+3wIr3zzOd/ziSICMzNL138odgFmZta1HPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZokrKOglTZG0WVK9pPmt7L9e0kZJGyRVSToxb98nkmqzx9rOLN7MzNqmtu6jl9QHeA24CNgOrAe+HhEb89p8CfhTRHwg6RrgvIi4Itv3XkQc1VUvwMzMDq5vAW0mAPURsRVA0nJgKtAc9BGxLq/9c8CVh1rQ8ccfHyNHjjzUw83MeqWampp/i4ghre0rJOiHAm/mrW8HvniQ9lcD/5K3XiKpGmgCFkTEP7c8QNJsYDbAiBEjqK6uLqAsMzPbT9KfD7SvkKBvzxNdCVQA5+ZtPjEidkg6CXhG0ssRsSX/uIhYDCwGqKio8JwMZmadqJA3Y3cAw/PWh2XbPkXShcAPgcsi4qP92yNiR/Z1K/CvwPgO1GtmZu1USNCvB06RVCrpCKAS+NTdM5LGAw+RC/m387YPktQ/Wz4emETe2L6ZmXW9NoduIqJJ0lzgKaAPsCQi6iTdAVRHxFrgHuAo4DFJANsi4jJgNPCQpH3kfqgsyL9bx8x6r48//pjt27ezd+/eYpdyWCkpKWHYsGH069ev4GPavL2yu1VUVITfjDVL3xtvvMHRRx/N4MGDyS4QrQ0RQWNjI++++y6lpaWf2iepJiIqWjvOn4w1s6LYu3evQ76dJDF48OB2/xbkoDezonHIt9+h9JmD3swscZ16H72Z2aG6/+nXOvV837/o1E49X2sWLVrEkUceyTe/+U2WLl3K5MmTOeGEEwD41re+xfXXX09ZWVmX19GW9IJ+3Y+75rxfuqlrzmtmh605c+Y0Ly9dupQxY8Y0B/0vf/nLYpX1GR66MbNeqaGhgVGjRjFjxgxGjx7NtGnT+OCDD6iqqmL8+PGMHTuWWbNm8dFHuc9/zp8/n7KyMsaNG8cNN9wAwO233869997LqlWrqK6uZsaMGZSXl/Phhx9y3nnnUV1dzaJFi7jxxhubn3fp0qXMnTsXgN/85jdMmDCB8vJyvvOd7/DJJ590yWt10JtZr7V582auvfZaNm3axDHHHMN9993HVVddxYoVK3j55ZdpamriF7/4BY2NjaxZs4a6ujo2bNjALbfc8qnzTJs2jYqKCpYtW0ZtbS0DBgxo3vfVr36VNWvWNK+vWLGCyspKNm3axIoVK/jDH/5AbW0tffr0YdmyZV3yOh30ZtZrDR8+nEmTJgFw5ZVXUlVVRWlpKaeemhvfnzlzJr///e859thjKSkp4eqrr+a3v/0tRx55ZMHPMWTIEE466SSee+45GhsbefXVV5k0aRJVVVXU1NRw1llnUV5eTlVVFVu3bu2S15neGL2ZWYFa3qo4cOBAGhsbP9Oub9++PP/881RVVbFq1Sp+9rOf8cwzzxT8PJWVlaxcuZJRo0Zx+eWXI4mIYObMmfz4x130vmIeX9GbWa+1bds2nn32WQAeeeQRKioqaGhooL6+HoCHH36Yc889l/fee489e/Zw6aWXcv/99/PSSy995lxHH3007777bqvPc/nll/P444/z6KOPUllZCcAFF1zAqlWrePvt3PRgu3fv5s9/PuBMwx3iK3oz6xG643bIlk477TQWLlzIrFmzKCsr46c//SkTJ05k+vTpNDU1cdZZZzFnzhx2797N1KlT2bt3LxHBfffd95lzXXXVVcyZM4cBAwY0//DYb9CgQYwePZqNGzcyYcIEAMrKyrjzzjuZPHky+/bto1+/fixcuJATTzzxM+fuqPTmuvHtlWaHhU2bNjF69OiiPX9DQwNf/vKXeeWVV4pWw6Fqre88142ZWS/moDezXmnkyJGH5dX8oXDQm5klzkFvZpY4B72ZWeIc9GZmifN99GbWM3T2rdFFviX6nXfe4ZFHHuHaa68F4C9/+Qvf/e53WbVqVbfX4it6M7Mu8M477/Dzn/+8ef2EE04oSsiDg97MeqmGhgZGjx7Nt7/9bU4//XQmT57Mhx9+yJYtW5gyZQpnnnkmZ599Nq+++ioAW7ZsYeLEiYwdO5ZbbrmFo446CoD33nuPCy64gDPOOIOxY8fy+OOPA7lpjbds2UJ5eTk33ngjDQ0NjBkzBoCJEydSV1fXXMv+KY3ff/99Zs2axYQJExg/fnzzuTrKQW9mvdbrr7/OddddR11dHQMHDmT16tXMnj2bBx98kJqaGu69997moZd58+Yxb948Xn75ZYYNG9Z8jpKSEtasWcMLL7zAunXr+MEPfkBEsGDBAk4++WRqa2u55557PvW8V1xxBStXrgRg586d7Ny5k4qKCu666y7OP/98nn/+edatW8eNN97I+++/3+HX6aA3s16rtLSU8vJyAM4880waGhr44x//yPTp05v/GMjOnTsBePbZZ5k+fToA3/jGN5rPERHcfPPNjBs3jgsvvJAdO3bw1ltvHfR5v/a1rzUP46xcuZJp06YB8Lvf/Y4FCxZQXl7Oeeedx969e9m2bVuHX6ffjDWzXqt///7Ny3369OGtt95i4MCB1NbWFnyOZcuWsWvXLmpqaujXrx8jR45k7969Bz1m6NChDB48mA0bNrBixQoWLVoE5H5orF69mtNOO+3QXtAB+IrezCxzzDHHUFpaymOPPQbkgnf/lMQTJ05k9erVACxfvrz5mD179vC5z32Ofv36sW7duuaphg82bTHkhm/uvvtu9uzZw7hx4wC4+OKLefDBB9k/2eSLL77YKa/LV/Rm1jP0kBlily1bxjXXXMOdd97Jxx9/TGVlJV/4whd44IEHuPLKK7nrrruYMmUKxx57LAAzZszgK1/5CmPHjqWiooJRo0YBMHjwYCZNmsSYMWO45JJLuO666z71PNOmTWPevHnceuutzdtuvfVWvve97zFu3Dj27dtHaWkpTzzxRIdfk6cpLlQP+SY0S0Wxpylurw8++IABAwYgieXLl/Poo4922l0x7dXeaYp9RW9mVoCamhrmzp1LRDBw4ECWLFlS7JIK5qA3MyvA2Wef3eqfEDwc+M1YMyuanjZ0fDg4lD5z0JtZUZSUlNDY2Oiwb4eIoLGxkZKSknYd56EbMyuKYcOGsX37dnbt2lXsUg4rJSUln/pkbiEc9GZWFP369aO0tLTYZfQKHroxM0tcQUEvaYqkzZLqJc1vZf/1kjZK2iCpStKJeftmSno9e8zszOLNzKxtbQa9pD7AQuASoAz4uqSyFs1eBCoiYhywCrg7O/Y44EfAF4EJwI8kDeq88s3MrC2FXNFPAOojYmtE/A1YDkzNbxAR6yLig2z1OWD/OwUXA09HxO6I+CvwNDClc0o3M7NCFBL0Q4E389a3Z9sO5GrgXw7xWDMz62SdeteNpCuBCuDcdh43G5gNMGLEiM4sycys1yvkin4HMDxvfVi27VMkXQj8ELgsIj5qz7ERsTgiKiKiYsiQIYXWbmZmBSgk6NcDp0gqlXQEUAmszW8gaTzwELmQfztv11PAZEmDsjdhJ2fbzMysm7Q5dBMRTZLmkgvoPsCSiKiTdAdQHRFrgXuAo4DHJAFsi4jLImK3pH8i98MC4I6I2N0lr8TMzFpV0Bh9RDwJPNli2215yxce5NglwOEzn6eZWWL8yVgzs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLXEFBL2mKpM2S6iXNb2X/OZJekNQkaVqLfZ9Iqs0eazurcDMzK0zfthpI6gMsBC4CtgPrJa2NiI15zbYBVwE3tHKKDyOivBNqNTOzQ9Bm0AMTgPqI2AogaTkwFWgO+ohoyPbt64IazcysAwoZuhkKvJm3vj3bVqgSSdWSnpP0j601kDQ7a1O9a9eudpzazMza0h1vxp4YERXAN4AHJJ3cskFELI6IioioGDJkSDeUZGbWexQS9DuA4Xnrw7JtBYmIHdnXrcC/AuPbUZ+ZmXVQIUG/HjhFUqmkI4BKoKC7ZyQNktQ/Wz4emETe2L6ZmXW9NoM+IpqAucBTwCZgZUTUSbpD0mUAks6StB2YDjwkqS47fDRQLeklYB2woMXdOmZm1sUKueuGiHgSeLLFttvylteTG9JpedwfgbEdrPGQPLu1sVPP91zTawW1+/5Fp3bq85qZdZQ/GWtmljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4goKeklTJG2WVC9pfiv7z5H0gqQmSdNa7Jsp6fXsMbOzCjczs8K0GfSS+gALgUuAMuDrkspaNNsGXAU80uLY44AfAV8EJgA/kjSo42WbmVmhCrminwDUR8TWiPgbsByYmt8gIhoiYgOwr8WxFwNPR8TuiPgr8DQwpRPqNjOzAhUS9EOBN/PWt2fbClHQsZJmS6qWVL1r164CT21mZoXoEW/GRsTiiKiIiIohQ4YUuxwzs6QUEvQ7gOF568OybYXoyLFmZtYJCgn69cApkkolHQFUAmsLPP9TwGRJg7I3YSdn28zMrJu0GfQR0QTMJRfQm4CVEVEn6Q5JlwFIOkvSdmA68JCkuuzY3cA/kfthsR64I9tmZmbdpG8hjSLiSeDJFttuy1teT25YprVjlwBLOlCjmZl1QI94M9bMzLqOg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEF/SlB6/nuf/q1oj339y86tWjPbWZt8xW9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJa6goJc0RdJmSfWS5reyv7+kFdn+P0kamW0fKelDSbXZY1Hnlm9mZm1p8w+PSOoDLAQuArYD6yWtjYiNec2uBv4aEX8vqRL4CXBFtm9LRJR3ct1mZlagQq7oJwD1EbE1Iv4GLAemtmgzFfh1trwKuECSOq9MMzM7VIUE/VDgzbz17dm2VttERBOwBxic7SuV9KKk/yPp7A7Wa2Zm7dTVfzN2JzAiIholnQn8s6TTI+Lf8xtJmg3MBhgxYkQXl2Rm1rsUEvQ7gOF568Oyba212S6pL3As0BgRAXwEEBE1krYApwLV+QdHxGJgMUBFRUUcwuvochO3LS6s4brBbbdp6Us3tf8Ys86y7sddd25/b/cIhQzdrAdOkVQq6QigEljbos1aYGa2PA14JiJC0pDszVwknQScAmztnNLNzKwQbV7RR0STpLnAU0AfYElE1Em6A6iOiLXAr4CHJdUDu8n9MAA4B7hD0sfAPmBOROzuihdiZmatK2iMPiKeBJ5sse22vOW9wPRWjlsNrO5gjWZm1gH+ZKyZWeIc9GZmiXPQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klrqvnujEzO+zc//RrRXne7190apec11f0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mlriCgl7SFEmbJdVLmt/K/v6SVmT7/yRpZN6+m7LtmyVd3Hmlm5lZIdoMekl9gIXAJUAZ8HVJZS2aXQ38NSL+Hrgf+El2bBlQCZwOTAF+np3PzMy6SSFX9BOA+ojYGhF/A5YDU1u0mQr8OlteBVwgSdn25RHxUUS8AdRn5zMzs27St4A2Q4E389a3A188UJuIaJK0BxicbX+uxbFDWz6BpNnA7Gz1PUmbC6r+044H/u0QjusObdR2c7cV0kKn9Nn1nVBICz3139J1tdvNPbW2HlnX9R2r68QD7Sgk6LtcRCwGFnfkHJKqI6Kik0rqVD21NtfVPq6r/Xpqbb2trkKGbnYAw/PWh2XbWm0jqS9wLNBY4LFmZtaFCgn69cApkkolHUHuzdW1LdqsBWZmy9OAZyIisu2V2V05pcApwPOdU7qZmRWizaGbbMx9LvAU0AdYEhF1ku4AqiNiLfAr4GFJ9cBucj8MyNqtBDYCTcB1EfFJF72WDg39dLGeWpvrah/X1X49tbZeVZdyF95mZpYqfzLWzCxxDnozs8QlEfRtTdFQLJIaJL0sqVZSdZFrWSLpbUmv5G07TtLTkl7Pvg7qIXXdLmlH1m+1ki4tQl3DJa2TtFFSnaR52fai9tlB6ipqn0kqkfS8pJeyuv5btr00mxalPpsm5YgeUtdSSW/k9Vd5d9aVV18fSS9KeiJb75r+iojD+kHuDeItwEnAEcBLQFmx68pqawCOL3YdWS3nAGcAr+RtuxuYny3PB37SQ+q6HbihyP31eeCMbPlo4DVyU4AUtc8OUldR+wwQcFS23A/4EzARWAlUZtsXAdf0kLqWAtOK+T2W1XQ98AjwRLbeJf2VwhV9IVM09HoR8Xtyd0Tly5+64tfAP3ZrURywrqKLiJ0R8UK2/C6widynuovaZwepq6gi571stV/2COB8ctOiQHH660B1FZ2kYcB/Bn6ZrYsu6q8Ugr61KRqK/o2fCeB3kmqyaR56mr+LiJ3Z8v8F/q6YxbQwV9KGbGin24eU8mWzsY4ndzXYY/qsRV1Q5D7LhiFqgbeBp8n9pv1ORDRlTYryf7NlXRGxv7/uyvrrfkn9u7su4AHgvwD7svXBdFF/pRD0Pdk/RMQZ5Gb+vE7SOcUu6EAi97tij7jSAX4BnAyUAzuB/16sQiQdBawGvhcR/56/r5h91kpdRe+ziPgkIsrJfQJ+AjCqu2toTcu6JI0BbiJX31nAccB/7c6aJH0ZeDsiarrj+VII+h47zUJE7Mi+vg2soefN3PmWpM8DZF/fLnI9AETEW9l/zn3A/6RI/SapH7kwXRYRv802F73PWqurp/RZVss7wDrgPwEDs2lRoMj/N/PqmpINgUVEfAT8L7q/vyYBl0lqIDfcfD7wP+ii/koh6AuZoqHbSfqPko7evwxMBl45+FHdLn/qipnA40Wspdn+IM1cThH6LRsv/RWwKSLuy9tV1D47UF3F7jNJQyQNzJYHABeRe/9gHblpUaA4/dVaXa/m/bAWuXHwbu2viLgpIoZFxEhymfVMRMygq/qr2O86d8YDuJTc3QdbgB8Wu56sppPI3QH0ElBX7LqAR8n9Sv8xubG/q8mNCVYBrwP/Gziuh9T1MPAysIFcsH6+CHX9A7lhmQ1Abfa4tNh9dpC6itpnwDjgxez5XwFuy7afRG5+q3rgMaB/D6nrmay/XgF+Q3ZnTjEewHn8/7tuuqS/PAWCmVniUhi6MTOzg3DQm5klzkFvZpY4B72ZWeIc9GZmiXPQm5klzkFvZpa4/wdnjHu9Uw9pFgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"xzxEI0CmGNEd"},"source":["## Metrics\n","\n","In this part of the assigment you will implement functions which computes accuracy and F1 score given groundtruth and predicted labels.\n","\n","### Accuracy\n","\n","Accuracy is defined as follows:\n","$$Accuracy = \\frac{\\textrm{Number of correct predictions}}{\\textrm{Total number of predictions}}$$\n","\n","### F1 score\n","F1 score is computed using precision and recall metrics, which are defined as follows:\n","$$precision = \\frac{TP}{TP + FP}$$\n","\n","$$recall = \\frac{TP}{TP + FN}$$\n","where TP, FP, FN stand for true positive, false positive and false negative samples, respectively.\n","\n","$$\\textrm{F1 score} = \\frac{2\\cdot precision\\cdot recall}{precision + recall}$$\n","\n","**Task:** **(Total 0.5 pts)**\n","* Implement a function which computes accuracy given true labels and predicted labels.\n","\n","* Check the documentation of `sklearn.metrics.f1_score` (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)."]},{"cell_type":"code","metadata":{"id":"b2uBN6f3GMsH"},"source":["def accuracy(y_true: np.array, y_pred: np.array) -> float:\n","    \"\"\"\n","    :param y_true: Ground truth labels.\n","    :param y_pred: Predicted labels.\n","    :return: Accuracy of the predictions.\n","    \"\"\"\n","\n","    #######################\n","    #### TODO YOUR CODE ###\n","    #######################\n","    correct = 0\n","    for i in range(len(y_true)):\n","      if y_true[i] == y_pred[i]:\n","        correct += 1\n","    return correct / len(y_true)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2nLGSFyKKur6"},"source":["## Thresholding\n","\n","Since $x_6 \\in [0, 1]$, a simple model can be created as follows:\n","\n","$$\\hat{y} = \\begin{cases}0, &\\text{if}\\ x_6 < T\\\\ 1, & \\text{otherwise} \\end{cases}$$\n","\n","where $T$ is hyperparameter representing a threshold.\n","\n","**Task:** **(Total: 2.5 pts)**\n","\n","* Implement `threshold` function which for given threshold `T` and feature `feature` computes the prediction $\\hat{y}$. **(0.5 pts)**\n","* Given a list of thresholds `thresholds` compute the accuracy and F1 score for each threshold on the training set. Use `sklearn.metrics.f1_score` and previously implemented `accuracy`. **(0.5 pts)**\n","* Which threshold would you select and why? (Just by looking at the plots, no need to run optimization).  **(0.5 pts)**\n","* Answer below why is F1 score better metric than accuracy in this particular case? **(1 pts)**\n","\n","**Answer:** TODO answer"]},{"cell_type":"code","metadata":{"id":"UfcA6rC_OGg6","colab":{"base_uri":"https://localhost:8080/","height":239},"executionInfo":{"status":"error","timestamp":1626145973381,"user_tz":-540,"elapsed":267,"user":{"displayName":"Changho Jin","photoUrl":"","userId":"15940163417036900361"}},"outputId":"265a3060-1898-46d9-a7c1-836bf9df942e"},"source":["thresholds = np.linspace(start=0., stop=1., num=20)\n","\n","def threshold(feature: np.array, T: float) -> np.array:\n","    \"\"\"\n","    :param feature: Using given feature a sample label is predicted.\n","    :param T: Threshold which is used to separate classes.\n","    \"\"\"\n","    #######################\n","    #### TODO YOUR CODE ###\n","    #######################\n","\n","#######################\n","#### TODO YOUR CODE ###\n","#######################\n","accuracies = None\n","f1_scores = f1_score\n","print(f1_scores)\n","\n","\n","plt.plot(thresholds, accuracies, label=\"Accuracy\")\n","plt.plot(thresholds, f1_scores, label=\"F1 Score\")\n","plt.legend()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-0fdfacace561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mf1_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'shape'"]}]},{"cell_type":"markdown","metadata":{"id":"rMIWp644jv-n"},"source":["## Baseline classifier\n","\n","Baseline classifier ignores sample feature and returns random probability, that a sample belongs to the class 1 (positive). (Hint probability is in range $[0, 1]$. Use `np.random.random`.)\n","\n","**Task:** **(Total: 0.5 pts)**\n","* Finish the implementation of the `RandomClassifier`."]},{"cell_type":"code","metadata":{"id":"CB1hnmoUk2m7"},"source":["class BaseClassifier:\n","    def prob_class_1(self, xs: np.array) -> np.array:\n","        \"\"\"\n","        :param xs: Input samples features.\n","        :return: Probability of a sample belonging to a class \"1\" (positive).\n","        \"\"\"\n","\n","        raise NotImplemented(\"prob_class_1 method not implemented.\")\n","\n","class RandomClassifier(BaseClassifier):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def prob_class_1(self, xs: np.array) -> np.array:\n","        #######################\n","        #### TODO YOUR CODE ###\n","        #######################\n","        return np.random.random(len(xs))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zQdgx9ALRGkV"},"source":["## Generative classifier\n","\n","In this part you will create generative classifiers based on gaussian probability distribution.\n","\n","Generative classifier tries to model the distributions of each class. Given the data, mean $\\mu$ and standard deviation $\\sigma$ of a gaussian distribution can be estimated as follows:\n","\n","$$\\mu = E[\\mathbf{X}] = \\frac{1}{N} \\sum_{i=1}^N X_i$$\n","\n","$$\\sigma = \\sqrt{E[(\\mathbf{X} - \\mu)^2]}$$\n","\n","where $N$  represents the number of samples $\\mathbf{X}$. $E[.]$ computes the average value of a given vector.\n","\n","**Task:** **(Total: 1 pts)**\n","* Compute the mean and standard deviation for each class (positive, negative) in the training set. You can use `np.mean`, Don|t use `np.std`.\n"]},{"cell_type":"code","metadata":{"id":"rYoJtzDDipdI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626153292087,"user_tz":-540,"elapsed":17,"user":{"displayName":"Changho Jin","photoUrl":"","userId":"15940163417036900361"}},"outputId":"d78a01e4-e506-47b1-9373-9c0858f56128"},"source":["#######################\n","#### TODO YOUR CODE ###\n","#######################\n","mean_pos = np.mean(train_set.pos)\n","std_pos = np.var(train_set.pos) ** (1/2)\n","mean_neg = np.mean(train_set.neg)\n","std_neg = np.var(train_set.neg) ** (1/2)\n","\n","print(f\"Mean positive: {mean_pos}\")\n","print(f\"Std. positive: {std_pos}\")\n","print(f\"Mean negative: {mean_neg}\")\n","print(f\"Std. negative: {std_neg}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean positive: 9.49053724053724\n","Std. positive: 13.116084506972172\n","Mean negative: 5.385416666666667\n","Std. negative: 10.171107112348833\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cX1-tS4hp3LV"},"source":["### Plotting the estimated distributions\n","\n","**Task:** **(Total: 1 pts)**\n","* From the estimated parameters create the gaussian distributions using `scipy.stats.norm(loc, scale)` where `loc` and `scale` represents $\\mu$ and $\\sigma$, respectively. **(0.5 pts)**\n","\n","* On top of the data distributions plotted using `plot_data`, plot the modeled gaussian distributions. Set range of x axis to $[-0.5, 1.5]$ (Sample x in that range as well). Sample the distributions using the method `.pdf(x)` of `scipy.stats.norm`. **(0.5 pts)**"]},{"cell_type":"code","metadata":{"id":"B_S8ins5rOXU"},"source":["#######################\n","#### TODO YOUR CODE ###\n","#######################\n","\n","x = None    # x values at which the distributions will be sampled.\n","norm_dist_pos = None\n","norm_dist_neg = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mHMnux7yscGJ"},"source":["### Computing the posterior probability\n","\n","Posterior probability (sample belonging to the class $c$ given data $x$) can be computed using the Bayes rule:\n","\n","$$P(y = c | x) \\frac{P(x|y=c)P(y=c)}{\\sum_{c'}P(x|y=c')P(y=c')}$$ \n","\n","where $P(x|y = c)$ are the previously estimated distributions. $P(y=c)$ is the class prior probability.\n","\n","The constructor of `GenerativeClassifier`takes the estimated normal distributions of samples in the training set and the prior probabilities.\n","\n","For more details: https://medium.com/swlh/understanding-gaussian-classifier-6c9f3452358f\n","\n","\n","**Task:** **(Total: 1 pts)**\n","* Implement the `prop_class_1` method, which returns the probability, that a sample belongs to the class 1 (positive). (Hint: use `.pdf` for sampling $P(x|y=c)$.)"]},{"cell_type":"code","metadata":{"id":"q1nmXAlTu7ST"},"source":["class GenerativeClassifier(BaseClassifier):\n","    def __init__(self, pos_norm, neg_norm, pos_prior: float, neg_prior: float):\n","        super().__init__()\n","\n","        self.pos_norm = pos_norm\n","        self.neg_norm = neg_norm\n","        self.pos_prior = pos_prior\n","        self.neg_prior = neg_prior\n","\n","    def prob_class_1(self, xs: np.array) -> np.array:\n","        #######################\n","        #### TODO YOUR CODE ###\n","        #######################\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M-HD8teiwvp0"},"source":["**Task:** **(Total: 1.5 pts)**\n","* Create a generative classifier `generative_classifier_flat_prior` with priors $P(y=1) = 0.5, P(y=0) = 0.5$. **(0.5 pts)**\n","\n","* Create a generative classifier `generative_classifier_full_prior` with priors $P(y=1) = 0.2, P(y=0) = 0.8$. **(0.5 pts)**\n","\n","* Plot both posterior probabilities over the train data histogram. Set range of x axis to $[-0.5, 1.5]$. (Hint: Sample the probabilities using `x`) **(0.5 pts)**"]},{"cell_type":"code","metadata":{"id":"njRiy93HwG_B"},"source":["x = np.linspace(start=-0.5, stop=1.5)\n","\n","#######################\n","#### TODO YOUR CODE ###\n","#######################\n","generative_classifier_flat_prior = None\n","generative_classifier_full_prior = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RgaOIaXhxpuA"},"source":["## Evaluation\n","\n","Given the `thresholds` threshold the probabilities and evaluate `RandomClassifier` and `GenerativeClassifier` (`generative_classifier_full_prior` as well as `generative_classifier_flat_prior`) using accuracy and F1 score on the **test set**.\n","\n","**Task:** **(Total: 2 pts)**\n","* Compute accuracies and F1 scores for `RandomClassifier` and `GenerativeClassifier` for each threshold. **(1 pts)**\n","\n","* Plot computed the accuracies on the y-axis with `thresholds` on the x-axis. **(0.5 pts)**\n","\n","\n","* Plot computed the F1 scores on the y-axis with `thresholds` on the x-axis. **(0.5 pts)**"]},{"cell_type":"code","metadata":{"id":"obiQgzElzCic"},"source":["#######################\n","#### TODO YOUR CODE ###\n","#######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8GMzkJn2X3x"},"source":["## Polynomial Regression\n","\n","Given data $y = sin(x)$, a noise will be added to the training data resulting in $y' = sin(x) + noise$.\n","\n","Retrieve the parameters of a polynomial model using `np.polyfit`, given the model parameters a model can be constructed using `np.poly1d`.\n","\n","See: https://numpy.org/doc/stable/reference/generated/numpy.poly1d.html\n","https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html\n","https://www.w3schools.com/python/python_ml_polynomial_regression.asp\n","\n","**Task:** **(Total 2.5 pts)**\n","* Implement a model learning the function $y$ given only $y'$ (`y_train`). **(0.5 pts)**\n","* Create two polynomial models with the **polynomial degree 3 and 15**. **(0.5 pts)**\n","* Using the test set compute and print the MSE error for each model - $MSE = \\frac{1}{N} \\sum(y - \\hat{y})^2$, where $\\hat{y}$, $N$ stands for predicted value and number of samples, respectively. **(0.5 pts)**\n","* Answer below, which model is better and why. **(1 pts)**\n","\n","**Answer:** TODO answer"]},{"cell_type":"code","metadata":{"id":"v78d2FD54Vdb"},"source":["from math import pi\n","\n","x = np.linspace(start=0, stop=2 * pi, num=100)\n","x_train = x[::2]\n","x_test = x[1::2]\n","\n","noise = np.random.randn(*x_train.shape) * 0.2\n","y_train = np.sin(x_train) + noise\n","y_test = np.sin(x_test)\n","\n","#######################\n","#### TODO YOUR CODE ###\n","#######################\n","reg_model_deg_3 = None\n","reg_model_deg_15 = None\n","\n","# plot model's learnt function\n","plt.plot(x_test, reg_model_deg_3(x_test), label=\"Deg: 3\")\n","plt.scatter(x_test, y_test, marker=\"+\", s=10, label=\"Test data\", c='#d62728')\n","plt.scatter(x_train, y_train, marker=\"+\", s=10, label=\"Train data\", c='#bcbd22')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(x_test, reg_model_deg_15(x_test), label=\"Deg: 15\")\n","plt.scatter(x_test, y_test, marker=\"+\", s=10, label=\"Test data\", c='#d62728')\n","plt.scatter(x_train, y_train, marker=\"+\", s=10, label=\"Train data\", c='#bcbd22')\n","plt.legend()"],"execution_count":null,"outputs":[]}]}